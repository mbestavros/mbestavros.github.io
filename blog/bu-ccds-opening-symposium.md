---
layout: layouts/post
title: "A Day of Learning - and New Ideas - at BU's shiny new CCDS"
subtitle: If only I could have studied here.
date: 2022-12-12
header-image: content/personal/ccds-grand-opening-header.jpg
tags:
    - tech
    - professional
    - security
    - thoughts
    - photography
---

# It's finally here!

As of Thursday, December 8th, 2022, Boston University's Center for Computing and Data Sciences (CCDS) is officially open for learning!

A striking statement piece of a building, it is a defining addition to Boston's skyline. It is also the physical realization of a small book of blueprints I snuck a peek at way back in 2015 - an inspiring set of images that gave me a (perhaps naive) hope that I'd someday be able to study there. Alas, I graduated from Boston University well before groundbreaking, let alone the grand opening. But seeing the new building in all its glory felt like full circle, somehow.

The grand opening ceremonies spanned two days. Thursday evening was the ribbon cutting, featuring some very eloquent speeches from Boston University leadership and trustees and Boston's Mayor Michelle Wu. On Friday morning and early afternoon, the Faculty of Computing and Data Sciences hosted a symposium for attending guests. Thanks to a fortuitous coincidence of timing, Friday also happened to be a Red Hat Day of Learning! It's as if the universe told me to go. So I did! And I thought I'd write up some brief reflections from the day.

While I had the privilege of attending several great talks and a panel, I'm going to narrow my focus to one talk in particular that got me really excited.

## The Promise and Peril of Synthetic Media

Hany Farid's talk, the second of the day, was my favorite by far - he is an incredibly engaging speaker. Hany started with an introduction to the concept of _synthetic media_: that is, media (pictures, video, or text) generated by a computer, or more specifically machine learning models. Projects like DALL-E, Stable Diffusion, and, most recently, ChatGPT have set the Internet ablaze with wacky creations originating from a single human-provided prompt. "Moai statue giving a TED talk?" [Sure!](https://www.reddit.com/r/weirddalle/comments/v96uct/moai_statue_giving_a_ted_talk/) "Fire hydrant takes selfies on top of the Himalayas?" [You betcha.](https://www.reddit.com/r/weirddalle/comments/vjwcl5/fire_hydrant_takes_selfies_on_top_of_the_himalaya/) "A guy from Dorchester complaining that Dunkin'Donuts shouldn't have changed their name to Dunkin?" [You're damn right they shouldn't have.](https://www.reddit.com/r/boston/comments/zefz81/artificial_intelligence_truly_understands_what/)

But beyond the good stuff to come out of these neural networks - things that make us laugh or bring us joy - there is, of course, a dark side to these innovations. The past few years have also seen incredible advances in _deepfake_ technology: the ability to fabricate images (and, more recently, video and audio) of real people. While impressive technically, this is also very problematic: **we are rapidly approaching a world where society cannot easily rely on our shared visual record.** Malicious actors can fabricate evidence of events that never happened, and use it to attack innocent people in the public conversation. Perhaps even worse, people who _have_ done something wrong now have a somewhat plausible excuse for dismissing visual evidence against them. _"No, I wasn't at the Capitol Riot. It was a deepfake."_

Beneath the surface, I've always felt a little bit of unease at the existence of such effective synthesis tools available to the public. I remember having a moment when ChatGPT burst onto the scene a few weeks ago thinking "this can probably also be used for incredibly effective misinformation. I'm not sure how to feel about it." Hany's talk served as an effective reminder: yes, as cool as these innovations are, they can be used for incredible malice. Society needs to be cognizant of that fact.

Fortunately, we have very smart people like Hany Farid thinking about these problems. The second part of his talk was a deep dive into how he and his lab are developing effective deepface detection tools, utilizing tons of subtle clues in an individual's behavior to determine whether an image or video is likely a deepfake or not. It was incredibly cool to see, and at least a little bit reassuring - even if this technology needs to become far more widespread to effectively combat such vast misinformation potential.

Believe it or not, though, none of that excited me nearly as much as a brief mention of a standards body called the **C2PA**, or: the **Coalition for Content Provenance and Authenticity**. The C2PA is a consortium of tech and media companies including Adobe, Microsoft, the BBC, and others attempting to solve misinformation by **digitally signing** different forms of media, so their provenance (where that content came from) can be verified later on.

Wait... provenance? Authenticity? Signing??? That's what I work on! That's Sigstore!!

This got the gears in my head moving REALLY quickly.

### A Brief Introduction to Sigstore

_(Feel free to skip this section if you're already aware of what Sigstore is and what it does.)_

[Sigstore](https://sigstore.dev) is a very cool project. Its goal is to make _software signing_ as easy and seamless as possible, with the aim of preventing _software supply chain attacks_.

What does that mean? Most modern software makes use of tons of interconnected dependencies. Of course, an unspoken assumption of these dependencies is that they come from a particular origin: a specific company, or a specific person. But what if that assumption is violated? What if some malicious actor manages to replace a part of a larger piece of software with a backdoored piece of code? Short answer: bad things happen. This is what's called a _supply chain attack_.

Fortunately, there's a pretty good way to combat these attacks: _software signing!_ Signing, in short, is the act of using cryptographic mechanisms like signatures and certificates to verify that something (a dependency, container image, binary, etc) was authored by a particular party, and that it hasnâ€™t changed since the author verified their ownership of it. This is a powerful tool - one that, if (theoretically) enforced for all dependencies in the software supply chain, would effectively deny any opportunity for a supply chain attack to happen in the first place. Which is great!

Unfortunately, code signing isn't nearly as ubiquitous as would be ideal. In the past, relevant signing tools have been fairly cumbersome, leaving only the most dedicated developers willing to sign their code and even fewer consumers willing to verify the software they use. That's why Sigstore was born: if software signing becomes as easy as possible, it will get adopted, and meaningfully improve supply chain security.

If you're curious about the different tools under the Sigstore umbrella, I wrote up a more detailed rundown in a [previous blog post.](https://mark.bestavros.net/blog/sigstore-in-a-nutshell/)

### It's All About Provenance

You may be able to see the common thread that went through my head during Hany Farid's talk already. Both Sigstore and the C2PA are fundamentally about **provenance**: providing information to end-of-chain consumers about where some artifact came from. And both projects aim to achieve provenance using signatures. Effectively, these two efforts are looking to solve the same fundamental problem, but for wildly different use cases.

Once I had that realization, a bunch of natural questions followed: could the Sigstore community's work apply to the C2PA? Are signed photographs and video generated with C2PA signatures compatible with Sigstore's tools? Is Sigstore the right tool for the job in the first place?

Let's put a pin in all that and back up a bit. What exactly does Sigstore do to make software signing better? Two things, which I'll call the "Sigstore provenance blueprint," for ease of reference:

- Sigstore's tooling makes the act of _signing_ software - that is, producing a signature that attests the origin and authenticity of something - far easier than before. Additionally, part of the Sigstore project's mission is to make this tooling available in as many places as possible.

- Sigstore's _signature transparency log_ implementation - run as a public-good service and available to all - allows for much easier _distribution_ of those signatures to the wider world. This allows consumers to _check_ the provenance of the software they use in a very straightforward, standardized way.

When combined, these two efforts make the entire chain of distributing and consuming software provenance a relatively easy process. So, next question: could this blueprint apply to visual media? Where does the C2PA fit in?

A quick perusal of the [C2PA Github organization](https://github.com/c2pa-org) suggests that this is a fairly young project as of late December 2022. There are a few draft specifications in different repositories, but no tooling available as of yet. However, there is a [repo](https://github.com/c2pa-org/public-testfiles) of test files that implement v1.0 of the C2PA spec. Very interesting!

So, it seems like the C2PA is working on the first part of the Sigstore provenance blueprint: producing signatures. Just like Sigstore, the C2PA's success will hinge on how widely these signatures get adopted by the industry: ideally, every camera and every piece of photo-editing software would produce signed photographs and video by default. That's a challenge for the C2PA to solve.

What about distribution - the second part of the blueprint? Well, once a signature has been produced, it's (theoretically) ready for Sigstore's transparency log. Okay, maybe someone needs to implement support for a new signature type or two - but fundamentally, C2PA signatures should fit right into the pre-existing Sigstore infrastructure!

Assuming that step works, the visual media provenance story beyond the transparency log layer should be largely the same as software signing: integrate into as many end-user applications as possible. On the code signing side, these developments are unfolding in real time - many different build/deploy/run pipelines are experimenting with including Sigstore provenance checks as part of their workflows.

The same thing could happen with visual media. The basic use case is almost exactly the same as with software signing: on a small scale, an easy-to-use tool could be made available to allow interested parties - journalists, activists, fact-checkers, researchers, etc. - to verify the provenance of a given photograph or video against Sigstore.

On a larger scale, the possibilities seem endless:

- Gallery apps could verify provenance and display it as part of the photo metadata! For example: who created the original media, whether it's been manipulated since creation, what device created it, etc.
- User-generated video sites (YouTube, TikTok, Instagram, etc.) could enforce provenance and proof-of-ownership as part of the upload process!
- Web browsers could verify image provenance automatically whenever an image is fetched, and warn (or block entirely) if some element of the provenance metadata is suspect!

If these mechanisms become widespread enough, they could very possibly become an extremely effective tool to combat misinformation in visual media. Of course, there are some very significant open questions with this approach, and I would be remiss in my duty as a responsible, ethical technologist to ignore those caveats. Let's play devil's advocate for a little bit.

### The Caveats

The first potential problem is a big one - literally: how will this approach scale? Sigstore has certainly had to think about scale, but "dealing with all the signatures produced for software releases" is a microscopic challenge next to "dealing with all the signatures for _every photograph and video ever produced or edited_."

Now, it's not quite as bad as it may seem at first glance: presumably, if Sigstore (or a Sigstore-like project) were to accept signed visual media, they wouldn't be storing the photos or videos themselves - just the signatures. Even so, it's almost certain Sigstore would need some rethinking to handle the volume that it would be expected to handle with such a use case.

Then again, perhaps signing everything isn't the _feasible_ answer. While ubiquity would unlock the strongest, most robust anti-misinformation benefits, it isn't _required_ for provenance to do some good. For example, a signed image could serve as proof positive for someone acting in good faith (e.g. a world leader giving a recorded address). Misinformation in visual media can take many forms, and perfect shouldn't be the enemy of good.

In a similar vein, my next big question around this approach would be _reliability_. Sigstore was designed for code signing, and was likely threat modeled with that use case in mind. However, it's not a stretch to imagine that the threats could be far worse with the visual record on the line. Is Sigstore ready to hold up against motivated misinformation peddlers, some of whom could be resourced by nation-states? Quite frankly, I don't know the answer, though Sigstore was designed with robustness in mind: as I alluded to before, it uses _transparency log_ technology underneath, which includes some very nice resilience properties. My tech lead Luke Hinds put out a great [explainer](https://blog.sigstore.dev/sigstore-blockchain-vs-transparency-logs-d673ea41a9be) a little while ago comparing transparency logs to blockchains; worth a read.

### Back to Hany Farid's Talk!

This entire essay has more or less been a much more verbose, well thought out version of the thoughts that raced through my head listening to Hany's talk. Fortunately, I was able to talk to the man himself! We had a brief but very engaging discussion about a few things, but most notably the idea of introducing signed visual media into Sigstore. It was a very satisfying end to a very wild (and intellectually satisfying) train of thought.

## A Building to be Proud Of

After the symposium concluded, the attendees were invited to lunch in the atrium of the new building. Meanwhile, we were also allowed to explore a poster session organized by BU Spark! (with my brother John presenting!) and a few guest lectures by the building's architects and collaborating BU professors.

The most interesting of these lectures, by far, was the sustainability presentation by Prof. Dennis Carlberg. I'd known this was an environmentally-friendly building, but I didn't realize _how deep_ that commitment from BU ran - literally. The building is heated and cooled through a series of geothermal wells reaching a staggering _1,500 feet_ into the ground! For scale, that's the equivalent of two whole John Hancock towers. Those wells allow the building to be heated and cooled on all but the most extreme-temperature days without using any other method of climate control, which I found deeply impressive (heh). In fact, there isn't a single fossil fuel line entering or exiting the entire building, for heat, electricity, or otherwise!

I was also struck by how well BU handled carbon offsets for CCDS. Obviously, the building is reliant on the local Massachusetts energy grid, which is not yet fully sustainable (as much as I wish it was). To offset the carbon produced by the local grid and meet their net zero emissions pledge, BU invested in a wind farm project in South Dakota that produces an equivalent amount of clean energy. The reason this is so significant: the produced clean energy is going into one of the single dirtiest power grids in the US, meaning that BU's investment is taking as much carbon out of the atmosphere per dollar as possible. Prof. Carlsberg went into detail on BU's search process for clean investment projects, and I'm willing to believe the institution did their due diligence here.

I like all this a lot. Bravo, BU - not only for giving computing students a learning space they deserve, but also making sure it's a place **everyone** can be proud of.

## Pictures!

Somewhat surprisingly, my photography game was not on point these two days. I have a few great shots worth sharing, but I should have gotten many more. I'll have to chalk it up to so much being on my mind - in a good way.

<div class="card-local-media">
{% responsiveImage, "content/personal/ccds-grand-opening-view-up.jpg", "" %}
</div>

_A view from right underneath the new building, It is truly enormous._

<div class="card-local-media">
{% responsiveImage, "content/personal/ccds-grand-opening-lineup.jpg", "" %}
</div>

_The speakers from the ribbon cutting ceremony on Thursday night. From left to right: Provost Jean Morrison, Dean Stan Sclaroff, Boston Mayor Michelle Wu, CDS Associate Provost Azer Bestavros (yes, THAT Bestavros), Board of Trustees Chair Ahmass Fakahany, and President Robert Brown._

<div class="card-local-media">
{% responsiveImage, "content/personal/ccds-grand-opening-professors.jpg", "" %}
</div>

_Five of the original BU Computer Science professors from the late 1990s. I've taken classes with every single one of them. From left to right: John Byers, Mark Crovella, Azer Bestavros, Wayne Snyder, and Abraham Matta._

<div class="card-local-media">
{% responsiveImage, "content/personal/ccds-grand-opening-atrium.jpg", "" %}
</div>

_A view of the main atrium, complete with seating areas for students. I'd love to post up there and work for a while..._

<div class="card-local-media">
{% responsiveImage, "content/personal/ccds-grand-opening-view-night.jpg", "" %}
</div>

_The multi-million-dollar night time view of Boston, looking east onto Kenmore Square, Back Bay, and downtown. The moon was out that night, and reflecting beautifully on the Charles River._

## Some housekeeping notes

I hope you enjoyed reading - this was a fun Friday, and I enjoyed reflecting on it! I'd say to stay tuned for more, but... regularity really isn't my forte, is it?

If you'd like to hear more of what I have to say, I do post all my new blog posts on my (very sparse otherwise) [Twitter](https://twitter.com/MBestavros) feed - feel free to follow me there if you haven't already. Though, as a good open source enthusiast (and perhaps also spurred on by Twitter's current events), I have also created a Mastodon account at [@mbestavros@fosstodon.org](https://fosstodon.org/@mbestavros). Feel free to follow me there as well!

Until next time. Have a great holiday season!

<div class="card-local-media">
{% responsiveImage, "content/personal/ccds-grand-opening-trees.jpg", "" %}
</div>
